{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6491388,"sourceType":"datasetVersion","datasetId":3751339},{"sourceId":6492025,"sourceType":"datasetVersion","datasetId":3751781},{"sourceId":6492276,"sourceType":"datasetVersion","datasetId":3751949},{"sourceId":7080300,"sourceType":"datasetVersion","datasetId":4078634},{"sourceId":7166993,"sourceType":"datasetVersion","datasetId":4140335}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Function\nimport torchvision\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.utils.data as util_data\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torchvision.datasets as dsets\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torchvision import models\nimport cv2\nimport time\n\nimport csv\nimport json\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nfrom typing import Any\nimport random\nimport torchvision","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-12T07:05:29.287627Z","iopub.execute_input":"2023-12-12T07:05:29.288749Z","iopub.status.idle":"2023-12-12T07:05:34.311351Z","shell.execute_reply.started":"2023-12-12T07:05:29.288701Z","shell.execute_reply":"2023-12-12T07:05:34.309894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_root = '/kaggle/input/palm6000/plam_6000'\ndataset_train_root = os.path.join(dataset_root, 'train')\ndataset_val_root = os.path.join(dataset_root, 'test/')\ndataset_all_dataset_root = os.path.join(dataset_root, 'all_dataset')\nnum_workers = 8\nnum_threads =8 \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.313594Z","iopub.execute_input":"2023-12-12T07:05:34.314290Z","iopub.status.idle":"2023-12-12T07:05:34.323059Z","shell.execute_reply.started":"2023-12-12T07:05:34.314230Z","shell.execute_reply":"2023-12-12T07:05:34.321817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs =200\n# epoch_lr_decrease = 100\nlearning_rate = 0.004\nencode_length =256\nnum_classes =600\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.324442Z","iopub.execute_input":"2023-12-12T07:05:34.325501Z","iopub.status.idle":"2023-12-12T07:05:34.340871Z","shell.execute_reply.started":"2023-12-12T07:05:34.325451Z","shell.execute_reply":"2023-12-12T07:05:34.339390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass SessionDataset(Dataset):   \n    def __init__(self, root, transform=None):    \n        self.labels = np.array([int(x.split('_')[0]) for x in os.listdir(path=root)])  \n        self.image_files = np.array([x.path for x in os.scandir(path=root)])     \n        self.transform = transform  \n    def __getitem__(self, index):       \n        img = cv2.imread(self.image_files[index])        \n        label = self.labels[index]\n        if self.transform:\n            img = self.transform(img)\n        \n        return img, label\n    \n    \n    def __len__(self):\n        return np.size(self.image_files)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.343887Z","iopub.execute_input":"2023-12-12T07:05:34.344296Z","iopub.status.idle":"2023-12-12T07:05:34.356423Z","shell.execute_reply.started":"2023-12-12T07:05:34.344263Z","shell.execute_reply":"2023-12-12T07:05:34.354772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transform = {\n    \"train\": transforms.Compose([\n        transforms.ToPILImage(),\n#         transforms.RandomResizedCrop((224, 224)),\n        transforms.RandomResizedCrop((128, 128)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),#转为Tensor\n        transforms.Normalize((0.51568358, 0.51568358, 0.51568358), (0.10332626, 0.10332626, 0.10332626)),#标准化处理\n        \n    ]),\n    \"val\": transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((128, 128)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.51568358, 0.51568358, 0.51568358), (0.10332626, 0.10332626, 0.10332626))\n\n    ]),\n    \"all_dataset\": transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((128, 128)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.51568358, 0.51568358, 0.51568358), (0.10332626, 0.10332626, 0.10332626))\n\n    ]),\n    \n}","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.358386Z","iopub.execute_input":"2023-12-12T07:05:34.358825Z","iopub.status.idle":"2023-12-12T07:05:34.370059Z","shell.execute_reply.started":"2023-12-12T07:05:34.358787Z","shell.execute_reply":"2023-12-12T07:05:34.368772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \ntrain_batch_size = 64#64\nval_batch_size = 64\n\nsession_train_dataset = SessionDataset(root=dataset_train_root,\n                                    transform=data_transform['train'])\n\ntrain_loader = DataLoader(session_train_dataset,\n                         batch_size=train_batch_size,\n                         shuffle=True,\n                         num_workers=num_workers)\nsession_val_dataset = SessionDataset(root=dataset_val_root,\n                                    transform=data_transform['val'])\nval_loader = DataLoader(session_val_dataset,\n                         batch_size=val_batch_size,\n                         shuffle=False,\n                         num_workers=num_workers)\nsessiondatabaseDataset = SessionDataset(root=dataset_all_dataset_root,\n                                    transform=data_transform['all_dataset'])\ndatabase_loader = DataLoader(sessiondatabaseDataset,\n                         batch_size=train_batch_size,\n                         shuffle=False,\n                         num_workers=num_workers)\ntrain_num = len(session_train_dataset)\nval_num = len(session_val_dataset)\ndatasetloader_num = len(sessiondatabaseDataset)\nprint(train_num, val_num,datasetloader_num)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.371602Z","iopub.execute_input":"2023-12-12T07:05:34.372545Z","iopub.status.idle":"2023-12-12T07:05:34.870069Z","shell.execute_reply.started":"2023-12-12T07:05:34.372500Z","shell.execute_reply":"2023-12-12T07:05:34.868797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Define the basic residual block\nclass BasicBlock(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes * self.expansion:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * self.expansion)\n            )\n\n    def forward(self, x):\n        out = self.bn1(self.conv1(x))\n        out = F.relu(out)\n        out = self.bn2(self.conv2(out))\n        out = F.relu(out)\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n# Define the ResNet-50 model\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        layers = []\n        layers.append(block(self.inplanes, planes, stride))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n# Create an instance of the ResNet-50 model\ndef original_resnet50(pretrained=False, progress=True, **kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.872130Z","iopub.execute_input":"2023-12-12T07:05:34.873134Z","iopub.status.idle":"2023-12-12T07:05:34.898613Z","shell.execute_reply.started":"2023-12-12T07:05:34.873087Z","shell.execute_reply":"2023-12-12T07:05:34.897163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Define the VGG block\nclass VGGBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, num_conv_layers):\n        super(VGGBlock, self).__init__()\n        layers = []\n        for _ in range(num_conv_layers):\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n            layers.append(nn.ReLU(inplace=True))\n            in_channels = out_channels\n        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n        self.block = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.block(x)\n\n# Define the VGG model\nclass VGGNet(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(VGGNet, self).__init__()\n        self.features = nn.Sequential(\n            VGGBlock(3, 64, 2),\n            VGGBlock(64, 128, 2),\n            VGGBlock(128, 256, 3),\n            VGGBlock(256, 512, 3),\n            VGGBlock(512, 512, 3)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Create an instance of the VGGNet model\ndef vggnet(pretrained=False, **kwargs):\n    model = VGGNet(**kwargs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.900062Z","iopub.execute_input":"2023-12-12T07:05:34.900709Z","iopub.status.idle":"2023-12-12T07:05:34.922280Z","shell.execute_reply.started":"2023-12-12T07:05:34.900669Z","shell.execute_reply":"2023-12-12T07:05:34.920956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\n__all__ = ['iresnet50_cbam']\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\nclass CBAM(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(CBAM, self).__init__()\n        self.channel_gate = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(channels, channels // reduction, kernel_size=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels // reduction, channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n        self.spatial_gate = nn.Sequential(\n            nn.Conv2d(channels, channels // reduction, kernel_size=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels // reduction, channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Channel-wise attention\n        channel_avg = self.channel_gate(x)\n        x = x * channel_avg\n\n        # Spatial-wise attention\n        channel_max = self.spatial_gate(x)\n        x = x * channel_max\n\n        return x\n\nclass IBasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64, dilation=1):\n        super(IBasicBlock, self).__init__()\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        self.bn1 = nn.BatchNorm2d(inplanes, eps=1e-05,)\n        self.conv1 = conv3x3(inplanes, planes)\n        self.bn2 = nn.BatchNorm2d(planes, eps=1e-05,)\n        self.prelu = nn.PReLU(planes)\n        self.conv2 = conv3x3(planes, planes, stride)\n        self.bn3 = nn.BatchNorm2d(planes, eps=1e-05,)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n        out = self.bn1(x)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.prelu(out)\n        out = self.conv2(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        return out\n\nclass IResNet(nn.Module):\n    fc_scale = 7 * 7\n\n    def __init__(self, block, layers, dropout=0, num_features=512, zero_init_residual=False, groups=1, width_per_group=64, replace_stride_with_dilation=None, fp16=False):\n        super(IResNet, self).__init__()\n        self.fp16 = fp16\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.inplanes, eps=1e-05)\n        self.prelu = nn.PReLU(self.inplanes)\n        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n        self.bn2 = nn.BatchNorm2d(512 * block.expansion, eps=1e-05,)\n        self.dropout = nn.Dropout(p=dropout, inplace=True)\n        self.cbam = CBAM(512 * block.expansion)\n        self.fc = nn.Linear(4 * 512 * block.expansion * self.fc_scale, num_features)\n        self.features = nn.BatchNorm1d(num_features, eps=1e-05)\n        nn.init.constant_(self.features.weight, 1.0)\n        self.features.weight.requires_grad = False\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.normal_(m.weight, 0, 0.1)\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, IBasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                nn.BatchNorm2d(planes * block.expansion, eps=1e-05, ),\n            )\n        layers = []\n        layers.append(\n            block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(\n                block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        with torch.cuda.amp.autocast(self.fp16):\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.prelu(x)\n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n            x = self.layer4(x)\n            x = self.bn2(x)\n            x = self.dropout(x)\n            x = self.cbam(x)\n            x = torch.flatten(x, 1)\n        x = self.fc(x.float() if self.fp16 else x)\n        x = self.features(x)\n        return x\n\ndef iresnet50_cbam(pretrained=False, progress=True, **kwargs):\n    return IResNet(IBasicBlock, [3, 4, 14, 3], **kwargs)\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.924073Z","iopub.execute_input":"2023-12-12T07:05:34.924798Z","iopub.status.idle":"2023-12-12T07:05:34.966763Z","shell.execute_reply.started":"2023-12-12T07:05:34.924762Z","shell.execute_reply":"2023-12-12T07:05:34.965450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n \n\n\ndef logistic(x, k=1, x0=0):\n    \"\"\"\n    Logistic function: L / (1 + exp(-k * (x - x0)))\n    \n    Parameters:\n    - x: Input values\n    - k: Steepness of the curve (default: 1)\n    - x0: x-value of the sigmoid's midpoint (default: 0)\n    \n    Returns:\n    - Result of the logistic function\n    \"\"\"\n    return 1 / (1 + np.exp(-k * (x - x0)))\n\n\ndef new_dropout(x, level=0.5):  \n    if level < 0. or level >= 1:\n        raise Exception('Dropout level must be in interval [0, 1].')  \n    retain_prob = 1. - level  \n\n    sample = torch.from_numpy(np.array(logistic(0.3, 100))).to(device)\n\n\n    \n    x *=sample          \n    \n    x /= retain_prob   \n    return x\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.970320Z","iopub.execute_input":"2023-12-12T07:05:34.973172Z","iopub.status.idle":"2023-12-12T07:05:34.982537Z","shell.execute_reply.started":"2023-12-12T07:05:34.973125Z","shell.execute_reply":"2023-12-12T07:05:34.981331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass SecureRandomProjectionLayer(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(SecureRandomProjectionLayer, self).__init__()\n        self.random_projection_matrix = nn.Parameter(torch.randn(input_dim, output_dim) * 0.01, requires_grad=False)\n\n\n    def forward(self, x):\n        # Apply secure random projection\n        transformed_data = torch.matmul(x, self.random_projection_matrix)\n        return transformed_data\n# new layer\nclass hash(Function):\n    @staticmethod\n    def forward(ctx, input):\n\n        return torch.sign(input)    \n    @staticmethod\n    def backward(ctx, grad_output):\n        #input,  = ctx.saved_tensors\n        #grad_output = grad_output.data\n        return grad_output\ndef hash_layer(input):\n    return hash.apply(input)\n\n\nclass CNN_ResNet(nn.Module):\n    def __init__(self, encode_length, num_classes ):\n        super(CNN_ResNet, self).__init__()\n        self.res = original_resnet50(pretrained=False, num_features =60).to(device)\n        \n        self.res.fc = nn.Linear(in_features=2048, out_features=1024)\n        self.secure_projection = SecureRandomProjectionLayer(1024,1024)\n      \n        self.fc_plus = nn.Linear(1024, encode_length) \n        \n        # Add the secure random projection layer\n        \n        \n        self.fc = nn.Linear( encode_length, num_classes, bias=False)\n\n    def forward(self, x):\n        x = self.res(x)\n        \n        x = new_dropout(x)\n        \n        # Apply the secure random projection before x = self.fc_plus(x)\n        x = self.secure_projection(x)\n               \n        if x.dim() != 3:\n            x = x.view(x.size(0), -1, 1)\n\n        # Get the dimensions\n        n, j = x.shape[1], x.shape[2]\n\n        # Reshape x to have dimensions (batch_size, n, j)\n        x = x.view(x.size(0), n, j)\n\n        # Find the maximum element in each subspace\n        max_values, _ = x.max(dim=2)\n\n \n        x = self.fc_plus(max_values)\n\n        code = hash_layer(x)\n\n   \n        output = self.fc(code)\n        \n        return output, x, code\n    \n#net = CNN_ResNet(encode_length=encode_length, num_classes=num_classes).to(device)\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:34.987732Z","iopub.execute_input":"2023-12-12T07:05:34.988710Z","iopub.status.idle":"2023-12-12T07:05:35.008102Z","shell.execute_reply.started":"2023-12-12T07:05:34.988657Z","shell.execute_reply":"2023-12-12T07:05:35.006700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new layer\n \nclass STEBinarizationLayer(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input):\n        # Using the STE method for binarization during forward pass\n        ctx.save_for_backward(input)\n        return torch.sign(input)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # During backward pass, use a straight-through estimator (STE)\n        input, = ctx.saved_tensors\n        grad_input = grad_output.clone()\n        grad_input[input > 1] = 0\n        grad_input[input < -1] = 0\n        return grad_input\n\ndef ste_binarization_layer(input):\n    return STEBinarizationLayer.apply(input)\n\nclass CNN_ResNet(nn.Module):\n    def __init__(self, encode_length, num_classes):\n        super(CNN_ResNet, self).__init__()\n        self.res = original_resnet50(pretrained=False, num_classes=1000).to(device)\n        self.res.fc = nn.Linear(in_features=2048, out_features=1000, bias=True)\n        self.fc_plus = nn.Linear(1000, encode_length)\n        self.fc = nn.Linear(encode_length, num_classes, bias=False)\n\n    def forward(self, x):\n        x = self.res(x)\n        x = self.fc_plus(x)\n        # Use STE for binarization\n        code = ste_binarization_layer(x)\n        output = self.fc(code)\n        return output, x, code\n\n# Example usage\n#net = CNN_ResNet(encode_length=encode_length, num_classes=num_classes).to(device)\nprint('ok')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:35.009581Z","iopub.execute_input":"2023-12-12T07:05:35.010490Z","iopub.status.idle":"2023-12-12T07:05:35.026108Z","shell.execute_reply.started":"2023-12-12T07:05:35.010443Z","shell.execute_reply":"2023-12-12T07:05:35.024795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \n# new layer\nclass hash(Function):\n    @staticmethod\n    def forward(ctx, input):\n\n        return torch.sign(input)    \n    @staticmethod\n    def backward(ctx, grad_output):\n        #input,  = ctx.saved_tensors\n        #grad_output = grad_output.data\n        return grad_output\ndef hash_layer(input):\n    return hash.apply(input)\n\n\n    \n    \nclass CNN_ResNet(nn.Module):\n    def __init__(self, encode_length, num_classes):\n        super(CNN_ResNet, self).__init__()\n        self.res =vggnet(pretrained=False,num_classes=1000).to(device)\n    \n        self.res.fc = nn.Linear(in_features=2048, out_features=1000)\n      \n        self.fc_plus = nn.Linear(1000, encode_length) \n        \n        self.fc = nn.Linear(encode_length, num_classes, bias=False)\n\n    def forward(self, x):\n        \n        x = self.res(x)\n        x = new_dropout(x)\n        x = self.fc_plus(x)\n\n        code = hash_layer(x)\n   \n        output = self.fc(code)\n        \n  \n        return output, x, code\n    \nnet = CNN_ResNet(encode_length=encode_length, num_classes=num_classes).to(device)\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:35.027654Z","iopub.execute_input":"2023-12-12T07:05:35.028816Z","iopub.status.idle":"2023-12-12T07:05:36.737788Z","shell.execute_reply.started":"2023-12-12T07:05:35.028768Z","shell.execute_reply":"2023-12-12T07:05:36.735478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:36.739332Z","iopub.execute_input":"2023-12-12T07:05:36.739782Z","iopub.status.idle":"2023-12-12T07:05:36.747924Z","shell.execute_reply.started":"2023-12-12T07:05:36.739740Z","shell.execute_reply":"2023-12-12T07:05:36.746670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compress(train, test, model, classes=600):\n    retrievalB = list([])\n    retrievalL = list([])\n    with torch.no_grad():\n        for batch_step, (data, target) in enumerate(train):         \n            var_data = data.to(device)            \n            _,_, code = model(var_data)        \n            retrievalB.extend(code.cpu().data.numpy())\n            retrievalL.extend(target)\n         \n        queryB=list([])\n        queryL=list([])\n        for batch_step, (data, target) in enumerate(test):     \n            var_data = data.to(device)\n            _,_, code = model(var_data)\n            \n            queryB.extend(code.cpu().data.numpy())\n            queryL.extend(target)\n            \n        retrievalB=np.array(retrievalB)\n        retrievalL=np.eye(classes)[np.array(retrievalL)]\n            \n        queryB=np.array(queryB)\n        queryL=np.eye(classes)[np.array(queryL)]   \n        \n            \n        return retrievalB, retrievalL, queryB, queryL\n\n\ndef calculate_hamming1(B1, B2):\n    \"\"\"\n    :param B1:  vector [n]\n    :param B2:  vector [r*n]\n    :return: hamming distance [r]\n    \"\"\"\n    if len(B1.shape) == 1:\n        B1 = np.expand_dims(B1, axis=0)  # Convert B1 to a 2D array if it's 1D\n\n    q = B2.shape[1]  # max inner product value\n    distH = 0.5 * (q - np.dot(B1, B2.transpose()))\n    return distH\n  \n    \ndef calculate_hamming(B1, B2):\n    \"\"\"\n    :param B1:  vector [n]\n    :param B2:  vector [r*n]\n    :return: hamming distance [r]\n    \"\"\"\n    q = B2.shape[1] # max inner product value\n    distH = 0.5 * (q - np.dot(B1, B2.transpose()))\n    return distH\n\n\ndef calculate_map(qB, rB, queryL, retrievalL):\n    \"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"\n    num_query = queryL.shape[0]\n    map = 0\n    for iter in range(num_query):\n       \n        gnd = (np.dot(queryL[iter, :], retrievalL.transpose()) > 0).astype(np.float32)\n        \n        tsum = np.sum(gnd).astype(int)\n        if tsum == 0:\n            continue\n        \n        hamm = calculate_hamming(qB[iter, :], rB)\n        ind = np.argsort(hamm)\n        gnd = gnd[ind]\n\n        count = np.linspace(1, tsum, tsum) # [1,2, tsum]\n        tindex = np.asarray(np.where(gnd == 1)) + 1.0\n        map_ = np.mean(count / (tindex))\n       \n        map = map + map_\n    map = map / num_query\n    return map\n\n\n\ndef calculate_top_map(qB, rB, queryL, retrievalL, topk):\n    \"\"\"\n    :param qB: {-1,+1}^{mxq} query bits\n    :param rB: {-1,+1}^{nxq} retrieval bits\n    :param queryL: {0,1}^{mxl} query label\n    :param retrievalL: {0,1}^{nxl} retrieval label\n    :param topk:\n    :return:\n    \"\"\"\n    num_query = queryL.shape[0]\n    topkmap = 0\n    for iter in range(num_query):\n        \n       \n        gnd = (np.dot(queryL[iter, :], retrievalL.transpose()) > 0).astype(np.float32)\n        hamm = calculate_hamming(qB[iter, :], rB)\n        ind = np.argsort(hamm)\n        gnd = gnd[ind]\n\n        tgnd = gnd[0:topk]\n        tsum = np.sum(tgnd).astype(int)\n        if tsum == 0:\n            continue\n        count = np.linspace(1, tsum, tsum)\n\n        tindex = np.asarray(np.where(tgnd == 1)) + 1.0\n        topkmap_ = np.mean(count / (tindex))\n      \n        topkmap = topkmap + topkmap_\n    topkmap = topkmap / num_query\n    return topkmap\n\n\n\ndef myCalcTopMap(rB, qB, retrievalL, queryL, topk):\n    \n    \n    num_query = queryL.shape[0]\n    \n    topkmap = 0\n    \n    \n    for iter in tqdm(range(num_query)):\n        \n        \n        gnd = (np.dot(queryL[iter, :], retrievalL.transpose()) > 0).astype(np.float32)\n        \n        \n        hamm = CalcHammingDist(qB[iter, :], rB)\n        \n        \n        ind = np.argsort(hamm)\n        \n       \n        gnd = gnd[ind]\n        \n        \n        tgnd = gnd[0:topk]\n        \n       \n        tsum = np.sum(tgnd).astype(int)\n        if tsum == 0:\n            continue\n        \n       \n        count = np.linspace(1, tsum, tsum)\n        \n        \n        tindex = np.asarray(np.where(tgnd == 1)) + 1.0\n        \n        \n        topkmap_ = np.mean(count / (tindex))\n        \n        topkmap = topkmap + topkmap_\n   \n    topkmap = topkmap / num_query\n    \n    return topkmap","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:36.749826Z","iopub.execute_input":"2023-12-12T07:05:36.750234Z","iopub.status.idle":"2023-12-12T07:05:36.772213Z","shell.execute_reply.started":"2023-12-12T07:05:36.750201Z","shell.execute_reply":"2023-12-12T07:05:36.770961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练过程\nimport matplotlib.pyplot as plt\n\n# Initialize an empty list to store accuracy values for each epoch\nepoch_accuracies = []\nbest = 0.0\n\ntorch.set_num_threads(num_threads)\n\nif torch.cuda.device_count() > 1:\n    net = nn.DataParallel(net)    \nnet.to(device)\n# Train the Model\nfor epoch in range(num_epochs):  \n    net.train()\n\n    \n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward + Backward + Optimize\n        optimizer.zero_grad()\n        outputs, feature, _ = net(images)\n\n\n        loss1 = criterion(outputs, labels)\n  \n        loss2 = torch.mean(torch.abs(torch.pow(torch.abs(feature) - torch.ones(feature.size()).to(device), 3)))\n        loss = loss1 + 0.1 * loss2\n        loss.backward()\n        optimizer.step()\n\n#         if (i + 1) % (len(oxford102TrainDataset) // batch_size / 2) == 0:\n        print ('Epoch [%d/%d], Iter [%d/%d] Loss1: %.4f Loss2: %.4f'\n               % (epoch + 1, num_epochs, i + 1, len(sessiondatabaseDataset) // train_batch_size,\n                  loss1.item(), loss2.item()))\n\n   \n    net.eval()  \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n           \n            outputs, _, _ = net(images)\n          \n            _, predicted = torch.max(outputs.cpu().data, 1)\n\n            total += labels.size(0)\n\n            correct += (predicted == labels).sum()\n\n    print('Test Accuracy of the model: %.2f %%' % (100.0 * correct / total))\n\n    if 1.0 * correct / total > best:\n        best = 1.0 * correct / total\n        torch.save(net.state_dict(), 'temp44.pkl')    \n    print('best: %.2f %%' % (best * 100.0))\n    net.eval()\n    retrievalB, retrievalL, queryB, queryL = compress(train_loader, val_loader, net)\n    print('---calculate map1---')\n    result1 = calculate_map(qB=queryB, rB=retrievalB, queryL=queryL, retrievalL=retrievalL)\n    #torch.save(net.state_dict(), 'map1_{}_module_all_obj.pkl'.format(round(result1,3)))\n    print(result1)\n    retrievalB, retrievalL, queryB, queryL = compress(database_loader, val_loader, net)\n    print('---calculate map2---')\n    result2 = calculate_map(qB=queryB, rB=retrievalB, queryL=queryL, retrievalL=retrievalL)\n    print(result2)\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-12-12T07:05:36.774140Z","iopub.execute_input":"2023-12-12T07:05:36.774497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    epoch_accuracies.append(result2)\n        #torch.save(net.state_dict(), 'map2_{}_module_all_obj.pkl'.format(round(result2,3)))\n    genuine_scores = []  # Store positive scores\n    imposter_scores = []  # Store negative scores\n\n    with torch.no_grad():\n        for i in range(len(queryB)):\n            for j in range(len(retrievalB)):\n                if np.all(queryL[i] == retrievalL[j]):  # Genuine pair\n                    queryB_tensor = torch.from_numpy(queryB[i])  # Convert to a PyTorch tensor\n                    retrievalB_tensor = torch.from_numpy(retrievalB[j])  # Convert to a PyTorch tensor\n                    genuine_scores.append(-1 * torch.dist(queryB_tensor, retrievalB_tensor, p=2).item())\n                else:  # Imposter pair\n                    queryB_tensor = torch.from_numpy(queryB[i])  # Convert to a PyTorch tensor\n                    retrievalB_tensor = torch.from_numpy(retrievalB[j])  # Convert to a PyTorch tensor\n                    imposter_scores.append(-1 * torch.dist(queryB_tensor, retrievalB_tensor, p=2).item())\n\n    # Set a threshold (you may need to fine-tune this)\n    threshold = 0.0  # Adjust the threshold as needed\n\n    # Calculate FAR and FRR\n    far = np.mean(np.array(imposter_scores) >= threshold)\n    frr = np.mean(np.array(genuine_scores) < threshold)\n\n    # Calculate EER\n    eer = 0.5  # Initialize EER\n    threshold_range = np.linspace(min(imposter_scores), max(genuine_scores), num=1000)\n\n    for t in threshold_range:\n        far_t = np.mean(np.array(imposter_scores) >= t)\n        frr_t = np.mean(np.array(genuine_scores) < t)\n\n        if abs(far_t - frr_t) < abs(far - frr):\n            far, frr = far_t, frr_t\n            eer = 0.5 * (far + frr)\n\n    print(f'FAR: {far * 100:.2f}%')\n    print(f'FRR: {frr * 100:.2f}%')\n    print(f'EER: {eer * 100:.2f}%')\n\n# Plot the accuracy vs. epoch graph\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, num_epochs + 1), epoch_accuracies, marker='o', linestyle='-')\nplt.title('Accuracy vs. Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (result2)')\nplt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}